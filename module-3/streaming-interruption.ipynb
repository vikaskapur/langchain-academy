{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658c7eea-7508-4efd-83ba-476c3f07f752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc776ffc-4e1b-4d06-8662-5b5064aa6362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.1\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "# (py < 3.11) from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatVertexAI(model=\"gemini-pro\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "\n",
    "# def call_model(state: State, config: RunnableConfig):\n",
    "def call_model(state: State):    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    # response = model.invoke(messages, config)\n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 4:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] {'conversation': {'messages': AIMessage(content=\"Hello Lance, it's nice to meet you! What would you like to talk about today?\", additional_kwargs={}, response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.055908203125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0255126953125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.111328125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0302734375}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10107421875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.023681640625}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.193359375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.07568359375}], 'usage_metadata': {'prompt_token_count': 6, 'candidates_token_count': 20, 'total_token_count': 26, 'cached_content_token_count': 0}, 'finish_reason': 'STOP', 'avg_logprobs': -0.20439915657043456}, id='run-ca5efea1-45f0-4329-a233-faaf79f57704-0', usage_metadata={'input_tokens': 6, 'output_tokens': 20, 'total_tokens': 26})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "chunk_cnt = 0\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(f\"[{chunk_cnt}] {chunk}\")\n",
    "    chunk_cnt+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance, it's nice to meet you! What would you like to talk about today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance, it's nice to meet you! What would you like to talk about today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: __start__. Type: on_chain_start. Name: __start__\n",
      "Node: __start__. Type: on_chain_start. Name: _write\n",
      "Node: __start__. Type: on_chain_end. Name: _write\n",
      "Node: __start__. Type: on_chain_start. Name: _write\n",
      "Node: __start__. Type: on_chain_end. Name: _write\n",
      "Node: __start__. Type: on_chain_stream. Name: __start__\n",
      "Node: __start__. Type: on_chain_end. Name: __start__\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatVertexAI\n",
      "Node: conversation. Type: on_chain_start. Name: _write\n",
      "Node: conversation. Type: on_chain_end. Name: _write\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Mumbai Indians team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='##', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.2177734375, 'blocked': False, 'severity': 'HARM_SEVERITY_LOW', 'severity_score': 0.2421875}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.119140625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1298828125}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.181640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1552734375}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.07373046875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.059326171875}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' Mumbai Indians:', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.19921875, 'blocked': False, 'severity': 'HARM_SEVERITY_LOW', 'severity_score': 0.283203125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.146484375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0634765625}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1630859375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.162109375}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.140625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.07568359375}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' A Dynasty in the Making\\n\\nThe Mumbai Indians are one of the most successful teams in the', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.337890625, 'blocked': False, 'severity': 'HARM_SEVERITY_LOW', 'severity_score': 0.232421875}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10986328125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.04541015625}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.193359375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1767578125}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09130859375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0517578125}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' history of the Indian Premier League (IPL), having won the coveted trophy a record', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.150390625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.14453125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1083984375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0279541015625}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1494140625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1025390625}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.068359375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.044677734375}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' five times (2013, 2015, 2017, 2019, and 2020).', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.11767578125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.111328125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10986328125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.029296875}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1142578125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0634765625}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.053466796875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0306396484375}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=\" Owned by Reliance Industries, the team boasts a star-studded lineup and a passionate fan base. Let's delve deeper into their journey and achievements:\\n\\n**\", additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10107421875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.07470703125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09521484375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0419921875}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0927734375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.042724609375}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0771484375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0279541015625}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=\"Dominant Force:**\\n\\n* **Five IPL titles:** Mumbai Indians hold the record for most IPL wins, surpassing Chennai Super Kings' four titles. Their consistent performance and ability to adapt to different conditions have been key to their success.\\n*\", additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0849609375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09033203125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09423828125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.036865234375}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08642578125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0390625}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.056640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0244140625}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' **Star-studded lineup:** The team boasts a formidable batting lineup with the likes of Rohit Sharma, Ishan Kishan, and Suryakumar Yadav. Their bowling attack is equally impressive, featuring Jasprit Bumrah, Trent Boult, and', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1142578125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.12353515625}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10107421875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.029296875}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09423828125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.06103515625}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.056640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0203857421875}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' Tymal Mills.\\n* **Experienced leadership:** Rohit Sharma, the captain, is a seasoned campaigner with vast experience in leading teams to victory. Head coach Mahela Jayawardene brings his cricketing acumen and tactical brilliance to the table.\\n\\n**Key Players:**\\n\\n* **Rohit Sharma:** The captain and opening batsman', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09033203125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09130859375}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08740234375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.032470703125}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09033203125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.059326171875}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.07373046875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0223388671875}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' is the backbone of the team. He is a prolific run-scorer and a master strategist.\\n* **Jasprit Bumrah:** The pace spearhead is arguably the best bowler in the world. His accuracy, pace, and variations make him a nightmare for batsmen.\\n* **Suryakumar Yadav:** The', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.12109375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.10986328125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08740234375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.03173828125}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10986328125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.08056640625}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08056640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0267333984375}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' stylish batsman is known for his innovative strokeplay and ability to score quickly.\\n* **Ishan Kishan:** The young wicketkeeper-batsman is a rising star with immense potential.\\n\\n**Challenges and Future:**\\n\\n* **Maintaining consistency:** The biggest challenge for Mumbai Indians will be to maintain their winning momentum. The', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09814453125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.12158203125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08056640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.037353515625}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09814453125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09033203125}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.06640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0267333984375}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' IPL is a highly competitive tournament, and other teams are constantly improving.\\n* **Building a strong bench:** Injuries and form fluctuations can derail even the best teams. Mumbai Indians need to build a strong bench of players who can step up when needed.\\n* **Adapting to changing trends:** The game of cricket is', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.078125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.103515625}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.07275390625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.03515625}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0849609375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.07470703125}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0771484375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0279541015625}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content=' constantly evolving. Mumbai Indians need to adapt their strategies and tactics to stay ahead of the curve.\\n\\n**Overall, the Mumbai Indians are a force to be reckoned with in the IPL. With their star-studded lineup, experienced leadership, and winning mentality, they are poised to continue their dominance in the years to come.**', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08154296875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.064453125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.037841796875}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09130859375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.09521484375}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.07568359375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0272216796875}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content='\\n\\n**Additional Information:**\\n\\n* **Home ground:** Wankhede Stadium, Mumbai\\n* **Coach:** Mahela Jayawardene\\n* **Captain:** Rohit Sharma\\n* **Official website:** https://www.mumbaiindians.com/\\n\\n**Please note that this information is accurate as of November 202', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.10107421875, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.14453125}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.07275390625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.05029296875}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.1083984375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.10107421875}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08056640625, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0341796875}]}, id='run-870e4347-7515-4585-a652-a9889b73ed59')}\n",
      "{'chunk': AIMessageChunk(content='3. There may have been changes to the team or its players since then.**', additional_kwargs={}, response_metadata={'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.09814453125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.1337890625}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.0693359375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.05029296875}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.099609375, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.099609375}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'probability_score': 0.08251953125, 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE', 'severity_score': 0.0361328125}], 'finish_reason': 'STOP'}, id='run-870e4347-7515-4585-a652-a9889b73ed59', usage_metadata={'input_tokens': 7, 'output_tokens': 604, 'total_tokens': 611})}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Mumbai Indians team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| San| Francisco| |49|ers| are| a| professional| American| football| team| based| in| the| San| Francisco| Bay| Area|.| They| compete| in| the| National| Football| League| (|NFL|)| as| a| member| of| the| league|'s| National| Football| Conference| (|N|FC|)| West| division|.| Here| are| some| key| points| about| the| team|:\n",
      "\n",
      "|###| History|\n",
      "|-| **|Founded|:**| |194|6| as| a| charter| member| of| the| All|-Amer|ica| Football| Conference| (|AA|FC|)| and| joined| the| NFL| in| |194|9| when| the| leagues| merged|.\n",
      "|-| **|Team| Name|:**| The| name| \"|49|ers|\"| is| a| reference| to| the| prospect|ors| who| arrived| in| Northern| California| during| the| |184|9| Gold| Rush|.\n",
      "\n",
      "|###| Ach|ievements|\n",
      "|-| **|Super| Bowl| Championships|:**| The| |49|ers| have| won| five| Super| Bowl| titles| (|X|VI|,| XIX|,| XX|III|,| XX|IV|,| and| XX|IX|).\n",
      "|-| **|Conference| Championships|:**| They| have| won| the| NFC| Championship| seven| times|.\n",
      "|-| **|Division| Championships|:**| The| team| has| numerous| NFC| West| division| titles|.\n",
      "\n",
      "|###| Not|able| Figures|\n",
      "|-| **|Co|aches|:**| Bill| Walsh|,| who| is| credited| with| developing| the| \"|West| Coast| offense|,\"| is| one| of| the| most| famous| coaches| in| |49|ers| history|.\n",
      "|-| **|Players|:**| The| team| has| had| several| Hall| of| Fame| players|,| including| Joe| Montana|,| Jerry| Rice|,| Steve| Young|,| Ronnie| L|ott|,| and| many| others|.\n",
      "\n",
      "|###| Stadium|\n",
      "|-| **|Le|vi|'s| Stadium|:**| Located| in| Santa| Clara|,| California|,| it| has| been| the| team's| home| since| |201|4|.| Before| that|,| they| played| at| Cand|lestick| Park| in| San| Francisco|.\n",
      "\n",
      "|###| Rival|ries|\n",
      "|-| **|Dallas| Cowboys|:**| One| of| the| most| stor|ied| rival|ries|,| especially| prominent| during| the| |198|0|s| and| |199|0|s|.\n",
      "|-| **|Seattle| Seahawks|:**| A| more| recent| but| intense| rivalry|,| particularly| since| the| Seahawks| joined| the| NFC| West| in| |200|2|.\n",
      "|-| **|Los| Angeles| Rams|:**| A| long|-standing| divis|ional| rivalry|.\n",
      "\n",
      "|###| Recent| Performance|\n",
      "|-| The| |49|ers| have| had| periods| of| both| success| and| struggle| in| recent| years|.| They| reached| the| Super| Bowl| in| the| |201|9| season| but| lost| to| the| Kansas| City| Chiefs|.| The| team| has| been| competitive| in| the| NFC| West| and| continues| to| build| a| strong| roster|.\n",
      "\n",
      "|###| Ownership| and| Management|\n",
      "|-| **|Owner|:**| The| team| is| owned| by| Denise| De|Bart|olo| York| and| John| York|,| with| their| son| Jed| York| serving| as| the| CEO|.\n",
      "|-| **|General| Manager|:**| John| Lynch|,| a| former| NFL| player| and| Hall| of| F|amer|,| has| been| the| GM| since| |201|7|.\n",
      "|-| **|Head| Coach|:**| Kyle| Shan|ahan|,| known| for| his| offensive| ac|umen|,| has| been| the| head| coach| since| |201|7|.\n",
      "\n",
      "|The| |49|ers| are| known| for| their| rich| history|,| iconic| players|,| and| significant| contributions| to| the| game| of| football|.| They| continue| to| be| a| prominent| and| competitive| team| in| the| NFL|.||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Mumbai Indian team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ade2276a-922d-4113-ac8b-056612d3bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##| Mumbai Indians: A Powerhouse in the IPL\n",
      "\n",
      " coveted trophy a record five times (2013, 2015, 2017, 2019, and |2020). Owned by Reliance Industries, the team boasts a star-studded lineup and a passionate fan base. Let's delve into the details of| this formidable franchise:\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "shan Kishan. This wealth of experience and talent makes them a force to be reckoned with.ld cricket, including Rohit Sharma, Jasprit Bumrah, Kieron Pollard, Suryakumar Yadav, and I|\n",
      " leadership has been instrumental in MI's success., is a seasoned campaigner with an impressive record in the IPL. His calm and composed|\n",
      "* **Balanced squad:** MI has a well-balanced squad with a strong batting lineup, a potent bowling attack, and reliable all-rounders. This versatility allows them to adapt to different situations and challenges.\n",
      " the Wankhede Stadium in Mumbai gives them a significant advantage. The pitch and conditions are familiar to the players, and the passionate home crowd provides them with immense support.\n",
      "\n",
      "**Recent Performance:**\n",
      "\n",
      " playoffs for the first time since 2018. This was a disappointing season for the team, but they will be looking to bounce back strong in the next edition.\n",
      " Their win percentage of 59.38% is the highest among all IPL teams. 133 and losing 91.|\n",
      "\n",
      "**Key Players:**\n",
      "\n",
      "* **Rohit Sharma:** The captain and star batsman is the backbone of the team. He is a prolific run-scorer and a shrewd tactician.\n",
      " The premier fast bowler is known for his accuracy, pace, and ability to swing the ball both ways. He is a vital cog in MI's bowling attack.\n",
      ". **Suryakumar Yadav:** The stylish batsman is a treat to watch with his innovative strokeplay. He is a key player in the middle order|\n",
      "* **Ishan Kishan:** The young wicketkeeper-batsman is a hard-hitting batsman who can take the game away from the opposition in a flash.\n",
      "\n",
      "**Looking Ahead:**\n",
      "\n",
      " record, they will be aiming to reclaim their title in the upcoming seasons. The team's management will be looking to address the weaknesses exposed in the 2023 season and build a squad capable of challenging for the championship once again.\n",
      "\n",
      "**Additional Information:**\n",
      "\n",
      "ene*Head Coach:** Mahela Jayaward|\n",
      "* **Home Ground:** Wankhede Stadium, Mumbai\n",
      "* **Team Colors:** Blue and Gold\n",
      "* **Official Website:** https://www.mumbaiindians.com/\n",
      "\n",
      "I hope this information provides a comprehensive overview of the Mumbai Indians. If you have any further questions, feel free to ask|!|"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Mumbai Indian team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "--\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
    "\n",
    "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
    "\n",
    "--\n",
    "\n",
    "The LangGraph API [has first class support for streaming](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#streaming). \n",
    "\n",
    "Let's load our `agent` in the Studio UI, which uses `module-3/studio/agent.py` set in `module-3/studio/langgraph.json`.\n",
    "\n",
    "The LangGraph API serves as the back-end for Studio.\n",
    "\n",
    "We can interact directly with the LangGraph API via the LangGraph SDK.\n",
    "\n",
    "We just need to get the URL for the local deployment from Studio.\n",
    "\n",
    "![Screenshot 2024-08-27 at 2.20.34 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf8943c3d4df239cbf0f_streaming2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if 'google.colab' in str(get_ipython()) or platform.system() != 'Darwin':\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab or requires a Mac\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# Replace this with the URL of your own deployed graph\n",
    "URL = \"http://localhost:56091\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '1ef6a3d0-41eb-66f4-a311-8ebdfa1b281f'})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '345c67cf-c958-4f89-b787-540fc025080c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-88179a6d-eb1e-4953-ac42-0b533b6d76f6', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': None}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': '4dd5ce10-ac0b-4a91-b34b-c35109dcbf29', 'tool_call_id': 'call_iIPryzZZxRtXozwwhVtFObNO', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is 6.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-b5862486-a25f-48fc-9a03-a8506a6692a8', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]})\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={'additional_kwargs': {'example': False, 'additional_kwargs': {}, 'response_metadata': {}}, 'response_metadata': {}, 'example': False} id='f51807de-6b99-4da4-a798-26cf59d16412'\n",
      "=========================\n",
      "content='' additional_kwargs={'additional_kwargs': {'tool_calls': [{'index': 0, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-fa4ab1c6-274d-4be5-8c4a-a6411c7c35cc' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_imZHAw7kvMR2ZeKaQVSlj25C', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {}, 'status': 'success'} name='multiply' id='3e7bbfb6-aa82-453a-969c-9c753fbd1d74' tool_call_id='call_imZHAw7kvMR2ZeKaQVSlj25C'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is 6.' additional_kwargs={'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'example': False, 'invalid_tool_calls': [], 'usage_metadata': None} id='run-e8e0d672-cfb2-42be-850a-345df3718f69'\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/complete\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50a85e16-6e3f-4f14-bcf9-8889a762f522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: Run ID - 1ef6a3da-687f-6253-915a-701de5327165\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "--------------------------------------------------\n",
      "Tool Calls:\n",
      "Tool Call ID: call_IL4MGMtr1fEpR3Yd9c2goLd8, Function: multiply, Arguments: {'a': 2, 'b': 3}\n",
      "Response Metadata: Finish Reason - tool_calls\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "AI: The\n",
      "--------------------------------------------------\n",
      "AI: The result\n",
      "--------------------------------------------------\n",
      "AI: The result of\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is \n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "--------------------------------------------------\n",
      "AI: The result of multiplying 2 and 3 is 6.\n",
      "Response Metadata: Finish Reason - stop\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
