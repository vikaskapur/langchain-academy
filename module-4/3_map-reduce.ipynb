{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd4f701",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/map-reduce.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239947-lesson-3-map-reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36737349-c949-4d64-9aa3-3767cbd02ad1",
   "metadata": {},
   "source": [
    "# Map-reduce\n",
    "\n",
    "## Review\n",
    "\n",
    "We're building up to a multi-agent research assistant that ties together all of the modules from this course.\n",
    "\n",
    "To build this multi-agent assistant, we've been introducing a few LangGraph controllability topics.\n",
    "\n",
    "We just covered parallelization and sub-graphs.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we're going to cover [map reduce](https://langchain-ai.github.io/langgraph/how-tos/map-reduce/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24e95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcd868a",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdc647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882fa913-0061-4d38-80df-d06cbf0321dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe9b9f-4375-4bca-8e32-7d57cb861469",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "Map-reduce operations are essential for efficient task decomposition and parallel processing. \n",
    "\n",
    "It has two phases:\n",
    "\n",
    "(1) `Map` - Break a task into smaller sub-tasks, processing each sub-task in parallel.\n",
    "\n",
    "(2) `Reduce` - Aggregate the results across all of the completed, parallelized sub-tasks.\n",
    "\n",
    "Let's design a system that will do two things:\n",
    "\n",
    "(1) `Map` - Create a set of jokes about a topic.\n",
    "\n",
    "(2) `Reduce` - Pick the best joke from the list.\n",
    "\n",
    "We'll use an LLM to do the job generation and selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "994cf903-1ed6-4ae2-b32a-7891a2808f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "\n",
    "# Prompts we will use\n",
    "subjects_prompt = \"\"\"Generate a list of 3 sub-topics that are all related to this overall topic: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \\n\\n  {jokes}\"\"\"\n",
    "\n",
    "# LLM\n",
    "model = ChatVertexAI(model=\"gemini-1.5-flash-002\", temperature=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b883cc-3469-4e96-b1a4-deadf7bf3ce5",
   "metadata": {},
   "source": [
    "## State\n",
    "\n",
    "### Parallelizing joke generation\n",
    "\n",
    "First, let's define the entry point of the graph that will:\n",
    "\n",
    "* Take a user input topic\n",
    "* Produce a list of joke topics from it\n",
    "* Send each joke topic to our above joke generation node\n",
    "\n",
    "Our state has a `jokes` key, which will accumulate jokes from parallelized joke generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "099218ca-ee78-4291-95a1-87ee61382e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int\n",
    "    \n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7176d1c-4a88-4b0f-a960-ee04a45279bd",
   "metadata": {},
   "source": [
    "Generate subjects for jokes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45010efd-ad31-4daa-b77e-aaec79ef0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    return {\"subjects\": response.subjects}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5296bb0-c163-4e5c-8181-1e305b37442a",
   "metadata": {},
   "source": [
    "Here is the magic: we use the [Send](https://langchain-ai.github.io/langgraph/concepts/low_level/#send) to create a joke for each subject.\n",
    "\n",
    "This is very useful! It can automatically parallelize joke generation for any number of subjects.\n",
    "\n",
    "* `generate_joke`: the name of the node in the graph\n",
    "* `{\"subject\": s`}: the state to send\n",
    "\n",
    "`Send` allow you to pass any state that you want to `generate_joke`! It does not have to align with `OverallState`.\n",
    "\n",
    "In this case, `generate_joke` is using its own internal state, and we can popular this via `Send`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc83e575-11f6-41a9-990a-adb571bcda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.constants import Send\n",
    "def continue_to_jokes(state: OverallState):\n",
    "    return [Send(\"generate_joke\", {\"subject\": s}) for s in state[\"subjects\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9847192d-d358-411e-90c0-f06be0738717",
   "metadata": {},
   "source": [
    "### Joke generation (map)\n",
    "\n",
    "Now, we just define a node that will create our jokes, `generate_joke`!\n",
    "\n",
    "We write them back out to `jokes` in `OverallState`! \n",
    "\n",
    "This key has a reducer that will combine lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcddc567-73d3-4fb3-bfc5-1bea538f2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokeState(TypedDict):\n",
    "    subject: str\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02960657-d174-4076-99a8-b3f9eea015f4",
   "metadata": {},
   "source": [
    "### Best joke selection (reduce)\n",
    "\n",
    "Now, we add logic to pick the best joke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d672870-75e3-4307-bda0-c41a86cbbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cd12e-5bff-426e-97f4-c774df998cfb",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ae6be4b-144e-483c-88ad-ce86d6477a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Construct the graph: here we put everything together to construct our graph\n",
    "graph = StateGraph(OverallState)\n",
    "graph.add_node(\"generate_topics\", generate_topics)\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"best_joke\", best_joke)\n",
    "graph.add_edge(START, \"generate_topics\")\n",
    "graph.add_conditional_edges(\"generate_topics\", continue_to_jokes, [\"generate_joke\"])\n",
    "graph.add_edge(\"generate_joke\", \"best_joke\")\n",
    "graph.add_edge(\"best_joke\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()\n",
    "Image(app.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e21dc7c9-0add-4125-be76-af701adb874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ServiceUnavailable: 503 Getting metadata from plugin failed with error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_topics': {'subjects': ['cat breeds', 'cat behavior', 'cat care']}}\n",
      "{'generate_joke': {'jokes': ['Why do cats make terrible comedians? Because they only have one-liners.']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_joke': {'jokes': ['Why was the cat sitting on the computer? To keep an eye on the mouse!']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_joke': {'jokes': ['Why was the cat sitting on the computer? To keep an eye on the mouse!']}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n",
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised ResourceExhausted: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff..\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_interceptor.py:332\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[1;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[1;32m    331\u001b[0m )\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, call\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_channel.py:440\u001b[0m, in \u001b[0;36m_InactiveRpcError.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See grpc.Future.result.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 440\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_channel.py:1198\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1192\u001b[0m (\n\u001b[1;32m   1193\u001b[0m     state,\n\u001b[1;32m   1194\u001b[0m     call,\n\u001b[1;32m   1195\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[1;32m   1196\u001b[0m     request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[1;32m   1197\u001b[0m )\n\u001b[0;32m-> 1198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_end_unary_response_blocking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/grpc/_channel.py:1006\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1006\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv6:%5B2404:6800:4002:813::200a%5D:443 {created_time:\"2025-01-19T23:18:43.750149+05:30\", grpc_status:8, grpc_message:\"Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff.\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the graph: here we call it to generate a list of jokes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/pregel/__init__.py:1660\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 1660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[1;32m   1667\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/pregel/runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/utils/runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m )\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langgraph/utils/runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[38], line 4\u001b[0m, in \u001b[0;36mbest_joke\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      2\u001b[0m jokes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjokes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m prompt \u001b[38;5;241m=\u001b[39m best_joke_prompt\u001b[38;5;241m.\u001b[39mformat(topic\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m], jokes\u001b[38;5;241m=\u001b[39mjokes)\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBestJoke\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_selected_joke\u001b[39m\u001b[38;5;124m\"\u001b[39m: state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjokes\u001b[39m\u001b[38;5;124m\"\u001b[39m][response\u001b[38;5;241m.\u001b[39mid]}\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:3020\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3018\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m   3019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3020\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/runnables/base.py:5352\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5347\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5348\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5349\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5350\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5353\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5354\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    285\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    647\u001b[0m ]\n\u001b[1;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m         )\n\u001b[1;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:1246\u001b[0m, in \u001b[0;36mChatVertexAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_gemini_model:\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_non_gemini(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_gemini\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:1416\u001b[0m, in \u001b[0;36mChatVertexAI._generate_gemini\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate_gemini\u001b[39m(\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1410\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1414\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[1;32m   1415\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request_gemini(messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1416\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gemini_response_to_chat_result(response)\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:616\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[0;34m(generation_method, max_retries, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    611\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    612\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    613\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    615\u001b[0m )\n\u001b[0;32m--> 616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/langchain_google_vertexai/chat_models.py:609\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry_inner\u001b[39m(generation_method: Callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2348\u001b[0m, in \u001b[0;36mPredictionServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2348\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/WORK_VIKAS/my-git-projects/langchain-academy/lc-academy-env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mResourceExhausted\u001b[0m: 429 Online prediction request quota exceeded for gemini-1.5-flash. Please try again later with backoff.",
      "\u001b[0mDuring task with name 'best_joke' and id '04add036-7eb8-58b6-d18a-a0459f50c997'"
     ]
    }
   ],
   "source": [
    "# Call the graph: here we call it to generate a list of jokes\n",
    "for s in app.stream({\"topic\": \"cat\"}):\n",
    "    print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a96517e-77ab-46e2-95e2-79168c044e9c",
   "metadata": {},
   "source": [
    "## Studio\n",
    "\n",
    "--\n",
    "\n",
    "**⚠️ DISCLAIMER**\n",
    "\n",
    "*Running Studio currently requires a Mac. If you are not using a Mac, then skip this step.*\n",
    "\n",
    "*Also, if you are running this notebook in CoLab, then skip this step.*\n",
    "\n",
    "--\n",
    "\n",
    "Let's load our the above graph in the Studio UI, which uses `module-4/studio/map_reduce.py` set in `module-4/studio/langgraph.json`.\n",
    "\n",
    "![Screenshot 2024-08-28 at 3.17.53 PM.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbb0c0ed88a12e822811e2_map-reduce1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a5e45-9a4c-43b4-8393-9298b3dcda53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
